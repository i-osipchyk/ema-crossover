{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3bc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/ivanosipchyk/dev/investing/ema-crossover\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time as timer\n",
    "import re\n",
    "import pytz\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from typing import List, Dict\n",
    "from datetime import datetime, timedelta, time\n",
    "\n",
    "target_dir = \"ema-crossover\"\n",
    "current_path = os.getcwd()\n",
    "\n",
    "while True:\n",
    "    if os.path.basename(current_path) == target_dir:\n",
    "        break\n",
    "    parent = os.path.dirname(current_path)\n",
    "    if parent == current_path:  # reached root, target not found\n",
    "        raise FileNotFoundError(f\"Directory '{target_dir}' not found in path hierarchy.\")\n",
    "    current_path = parent\n",
    "\n",
    "os.chdir(current_path)\n",
    "print(f\"Working directory set to: {os.getcwd()}\")\n",
    "\n",
    "from modules.tools import get_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "NY_TZ = pytz.timezone(\"America/New_York\")\n",
    "MARKET_OPEN = time(9, 30)\n",
    "MARKET_CLOSE = time(16, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a98abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_saved_file(data_dir: str) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve the most recently modified .pkl file in a directory.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): Path to the directory containing saved files.\n",
    "\n",
    "    Returns:\n",
    "        str: Full path to the latest saved file, or None if no files exist.\n",
    "    \"\"\"\n",
    "    saved_files = sorted(\n",
    "        [f for f in os.listdir(data_dir) if f.endswith(\".pkl\")],\n",
    "        key=lambda f: os.path.getmtime(os.path.join(data_dir, f)),\n",
    "        reverse=True\n",
    "    )\n",
    "    return os.path.join(data_dir, saved_files[0]) if saved_files else None\n",
    "\n",
    "\n",
    "def extract_timestamp(filename: str) -> datetime | None:\n",
    "    \"\"\"\n",
    "    Extract a datetime object from a filename based on the pattern YYYY-MM-DD_HH-MM-SS.\n",
    "\n",
    "    Args:\n",
    "        filename (str): The filename containing the timestamp.\n",
    "\n",
    "    Returns:\n",
    "        datetime | None: Localized datetime in NY_TZ if extraction succeeds, otherwise None.\n",
    "    \"\"\"\n",
    "    pattern = r\"(\\d{4}-\\d{2}-\\d{2}_\\d{2}-\\d{2}-\\d{2})\"\n",
    "    match = re.search(pattern, filename)\n",
    "    if match:\n",
    "        timestamp_str = match.group(1)\n",
    "        try:\n",
    "            file_dt = datetime.strptime(timestamp_str, \"%Y-%m-%d_%H-%M-%S\")\n",
    "            return NY_TZ.localize(file_dt)\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "\n",
    "def is_market_hour(current_dt: datetime) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a given datetime falls within U.S. market hours (9:30–16:00 ET, Mon–Fri).\n",
    "\n",
    "    Args:\n",
    "        current_dt (datetime): The datetime to check. Can be naive or timezone-aware.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if within market hours, False otherwise.\n",
    "    \"\"\"\n",
    "    if current_dt.tzinfo is None:\n",
    "        current_dt = current_dt.replace(tzinfo=pytz.utc)\n",
    "\n",
    "    current_dt_et = current_dt.astimezone(NY_TZ)\n",
    "\n",
    "    if current_dt_et.weekday() >= 5:\n",
    "        return False\n",
    "\n",
    "    return MARKET_OPEN <= current_dt_et.time() <= MARKET_CLOSE\n",
    "\n",
    "\n",
    "def find_closest_market_hour(current_dt: datetime) -> datetime:\n",
    "    \"\"\"\n",
    "    Find the most recent market hour in the past relative to a given datetime.\n",
    "    If executed during market hours, returns the current time.\n",
    "\n",
    "    Args:\n",
    "        current_dt (datetime): The reference datetime. Can be naive or timezone-aware.\n",
    "\n",
    "    Returns:\n",
    "        datetime: The closest market hour in NY_TZ.\n",
    "    \"\"\"\n",
    "    if current_dt.tzinfo is None:\n",
    "        current_dt = current_dt.replace(tzinfo=pytz.utc)\n",
    "\n",
    "    current_dt_et = current_dt.astimezone(NY_TZ)\n",
    "\n",
    "    # Return now for market hours\n",
    "    if is_market_hour(current_dt):\n",
    "        return current_dt_et\n",
    "\n",
    "    # If after market close today\n",
    "    if current_dt_et.weekday() < 5 and current_dt_et.time() > MARKET_CLOSE:\n",
    "        return datetime.combine(current_dt_et.date(), MARKET_CLOSE, NY_TZ)\n",
    "\n",
    "    # Otherwise, find last valid weekday close\n",
    "    days_checked = 0\n",
    "    while days_checked < 7:  # Safety stop\n",
    "        current_dt_et -= timedelta(days=1)\n",
    "        if current_dt_et.weekday() < 5:  # Monday–Friday\n",
    "            return datetime.combine(current_dt_et.date(), MARKET_CLOSE, NY_TZ)\n",
    "        days_checked += 1\n",
    "\n",
    "    raise RuntimeError(\"Could not find a valid market day within the past week.\")\n",
    "\n",
    "\n",
    "def compare_timestamps(latest: datetime, now: datetime, interval: str) -> bool:\n",
    "    \"\"\"\n",
    "    Compare two datetimes to determine if the difference is less than a specified interval.\n",
    "\n",
    "    Args:\n",
    "        latest (datetime): The previous timestamp.\n",
    "        now (datetime): The current timestamp.\n",
    "        interval (str): Interval string ('Xm', 'Xh', 'Xd') to compare.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the difference is less than the interval, False otherwise.\n",
    "    \"\"\"\n",
    "    if latest is None:\n",
    "        return False\n",
    "    \n",
    "    if interval.endswith(\"m\"):\n",
    "        delta = timedelta(minutes=int(interval[:-1]))\n",
    "    elif interval.endswith(\"h\"):\n",
    "        delta = timedelta(hours=int(interval[:-1]))\n",
    "    elif interval.endswith(\"d\"):\n",
    "        delta = timedelta(days=int(interval[:-1]))\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported interval format: {interval}\")\n",
    "    \n",
    "    return now - latest < delta\n",
    "\n",
    "\n",
    "def check_symbols(existing_symbols: List[str], requested_symbols: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check whether two lists of symbols are identical.\n",
    "    \"\"\"\n",
    "    return set(existing_symbols) == set(requested_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73176ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yf_data(symbols: List[str], period: str, interval: str, \n",
    "                batch_size: int = 100, delay: float = 0.1, add_tqdm: bool = True) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Get OHLCV data for multiple symbols using Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        symbols (List[str]): List of symbols to download.\n",
    "        period (str): Data period (e.g., \"1d\", \"5d\", \"1mo\", \"1y\").\n",
    "        interval (str): Candlestick interval (e.g., \"1m\", \"15m\", \"1h\", \"1d\").\n",
    "        batch_size (int, optional): Number of symbols per request batch. Defaults to 100.\n",
    "        delay (float, optional): Delay (in seconds) between batches to avoid rate limiting. Defaults to 0.1.\n",
    "        add_tqdm (bool, optional): Whether to display a progress bar. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Mapping of symbol → OHLCV DataFrame.\n",
    "            Each DataFrame contains: Datetime, Open, High, Low, Close, Volume, Symbol.\n",
    "    \"\"\"\n",
    "    if add_tqdm:\n",
    "        tqdm = get_tqdm()\n",
    "    else:\n",
    "        tqdm = lambda x, **kwargs: x\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "    num_batches = (len(symbols) - 1) // batch_size + 1\n",
    "\n",
    "    for i in tqdm(range(0, len(symbols), batch_size), desc=\"Downloading batches\", total=num_batches):\n",
    "        batch = symbols[i:i + batch_size]\n",
    "\n",
    "        try:\n",
    "            raw_df = yf.download(\n",
    "                tickers=batch,\n",
    "                period=period,\n",
    "                interval=interval,\n",
    "                group_by=\"ticker\",\n",
    "                progress=False,\n",
    "                threads=True,\n",
    "                ignore_tz=True,\n",
    "                auto_adjust=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "            timer.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        if raw_df.empty:\n",
    "            timer.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        # Normalize structure\n",
    "        raw_df = raw_df.reset_index(drop=False)\n",
    "        if isinstance(raw_df.columns, pd.MultiIndex):\n",
    "            raw_df.columns = [\n",
    "                f\"{symbol}_{field}\" if field else \"Datetime\"\n",
    "                for symbol, field in raw_df.columns\n",
    "            ]\n",
    "        else:\n",
    "            raw_df.columns = [\n",
    "                \"Datetime\" if col == \"Date\" else f\"{batch[0]}_{col}\"\n",
    "                for col in raw_df.columns\n",
    "            ]\n",
    "\n",
    "        # Extract data per symbol\n",
    "        for symbol in batch:\n",
    "            cols = [col for col in raw_df.columns if col.startswith(f\"{symbol}_\")]\n",
    "            if not cols:\n",
    "                continue\n",
    "\n",
    "            df_symbol = raw_df[[\"Datetime\"] + cols].copy()\n",
    "            df_symbol.columns = [\n",
    "                col.split(\"_\", 1)[1] if \"_\" in col else col\n",
    "                for col in df_symbol.columns\n",
    "            ]\n",
    "            df_symbol[\"Symbol\"] = symbol\n",
    "\n",
    "            # Leaves all requested symbols in the final dataframe, so that the list can be compared in the future\n",
    "            # if df_symbol.empty or df_symbol[\"Open\"].isna().all():\n",
    "            #     continue\n",
    "            \n",
    "            if df_symbol.empty:\n",
    "                continue\n",
    "\n",
    "            results[symbol] = df_symbol\n",
    "\n",
    "        timer.sleep(delay)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ac566bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "        symbols: List[str], period: str, interval: str,\n",
    "        batch_size: int = 100, delay: float = 0.1,\n",
    "        expected_root: str = \"/Users/ivanosipchyk/dev/investing/ema-crossover\") -> Dict[str, pd.DataFrame]:\n",
    "    \n",
    "    # 1. Move to root dir\n",
    "    current_dir = os.getcwd()\n",
    "    \n",
    "    if current_dir != expected_root:\n",
    "        raise RuntimeError(\n",
    "            f\"Current working directory is {current_dir}, but expected {expected_root}. \"\n",
    "            \"Please run this function from the project root.\"\n",
    "        )\n",
    "    \n",
    "    data_dir = os.path.join(current_dir, \"data\", \"historical_data\", interval)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    # 2. Get lastest saved file for a given interval\n",
    "    latest_file = get_latest_saved_file(data_dir, interval)\n",
    "\n",
    "    if latest_file:\n",
    "        # 3. Compare file timestamps with the closest market hour\n",
    "        latest_timestamp = extract_timestamp(latest_file)\n",
    "        closest_market_hour = find_closest_market_hour(datetime.now(pytz.timezone(\"America/New_York\")))\n",
    "        if compare_timestamps(latest_timestamp, closest_market_hour, interval):\n",
    "\n",
    "            # 4. Compare symbols\n",
    "            latest_data = pd.read_pickle(latest_file)\n",
    "            if check_symbols(list(latest_data.keys()), symbols):\n",
    "\n",
    "                # 5. Compare lenghts\n",
    "                check_symbol = next(iter(latest_data.keys()))\n",
    "                latest_check_df = latest_data[check_symbol]\n",
    "                new_check_df = get_yf_data([check_symbol], period, interval, batch_size, add_tqdm=False)\n",
    "\n",
    "                if len(new_check_df[check_symbol]) == len(latest_check_df):\n",
    "                    print(f\"✅ Data is up-to-date as of {latest_timestamp}, contains same symbols, and is the same length. No download needed.\")\n",
    "                    return latest_data\n",
    "\n",
    "    historical_data = get_yf_data(symbols, period, interval, batch_size, delay)\n",
    "   \n",
    "    filename = f\"historical_data_{datetime.now(NY_TZ).strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    "    save_path = os.path.join(data_dir, filename)\n",
    "\n",
    "    pd.to_pickle(historical_data, save_path)\n",
    "    print(f\"\\n✅ Saved all downloaded data to {save_path}\")\n",
    "\n",
    "    return historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a02e791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e0468ba5bdc48a691de56c5cbf87b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Saved all downloaded data to /Users/ivanosipchyk/dev/investing/ema-crossover/data/historical_data/1d/historical_data_2025-10-11_13-01-43.pkl\n"
     ]
    }
   ],
   "source": [
    "data = download_data(\n",
    "    symbols=['OKLO', 'MSFT'],\n",
    "    period = '200d',\n",
    "    interval = '1d',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5975776",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
