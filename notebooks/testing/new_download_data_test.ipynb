{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from typing import List, Dict\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "\n",
    "from modules.tools import get_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac566bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(\n",
    "    symbols: List[str],\n",
    "    period: str,\n",
    "    interval: str,\n",
    "    batch_size: int = 100,\n",
    "    delay: float = 0.1\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Download OHLCV data for multiple symbols using Yahoo Finance\n",
    "    and save all downloaded data as one .pkl file in data/historical_data.\n",
    "\n",
    "    Args:\n",
    "        symbols (List[str]): List of ticker symbols to download.\n",
    "        period (str): Data period (e.g., \"1d\", \"5d\", \"1mo\", \"1y\").\n",
    "        interval (str): Candlestick interval (e.g., \"1m\", \"15m\", \"1h\", \"1d\").\n",
    "        batch_size (int, optional): Number of symbols per request batch. Defaults to 100.\n",
    "        delay (float, optional): Delay (in seconds) between batches to avoid rate limiting. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Mapping of symbol → OHLCV DataFrame.\n",
    "    \"\"\"\n",
    "    tqdm = get_tqdm()\n",
    "\n",
    "    # === Ensure output directory exists ===\n",
    "    base_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    data_dir = os.path.join(base_dir, \"../../data/historical_data\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "    num_batches = (len(symbols) - 1) // batch_size + 1\n",
    "\n",
    "    for i in tqdm(range(0, len(symbols), batch_size), desc=\"Downloading batches\", total=num_batches):\n",
    "        batch = symbols[i:i + batch_size]\n",
    "\n",
    "        try:\n",
    "            raw_df = yf.download(\n",
    "                tickers=batch,\n",
    "                period=period,\n",
    "                interval=interval,\n",
    "                group_by=\"ticker\",\n",
    "                progress=False,\n",
    "                threads=True,\n",
    "                ignore_tz=True,\n",
    "                auto_adjust=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "            time.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        if raw_df.empty:\n",
    "            time.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        # Normalize structure\n",
    "        raw_df = raw_df.reset_index(drop=False)\n",
    "        if isinstance(raw_df.columns, pd.MultiIndex):\n",
    "            raw_df.columns = [\n",
    "                f\"{symbol}_{field}\" if field else \"Datetime\"\n",
    "                for symbol, field in raw_df.columns\n",
    "            ]\n",
    "        else:\n",
    "            raw_df.columns = [\n",
    "                \"Datetime\" if col == \"Date\" else f\"{batch[0]}_{col}\"\n",
    "                for col in raw_df.columns\n",
    "            ]\n",
    "\n",
    "        # Extract data per symbol\n",
    "        for symbol in batch:\n",
    "            cols = [col for col in raw_df.columns if col.startswith(f\"{symbol}_\")]\n",
    "            if not cols:\n",
    "                continue\n",
    "\n",
    "            df_symbol = raw_df[[\"Datetime\"] + cols].copy()\n",
    "            df_symbol.columns = [\n",
    "                col.split(\"_\", 1)[1] if \"_\" in col else col\n",
    "                for col in df_symbol.columns\n",
    "            ]\n",
    "            df_symbol[\"Symbol\"] = symbol\n",
    "\n",
    "            if df_symbol.empty or df_symbol[\"Open\"].isna().all():\n",
    "                continue\n",
    "\n",
    "            results[symbol] = df_symbol\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    # === Save entire dictionary as a single pickle file ===\n",
    "    filename = f\"historical_data_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}.pkl\"\n",
    "    save_path = os.path.join(data_dir, filename)\n",
    "    pd.to_pickle(results, save_path)\n",
    "    print(f\"\\n✅ Saved all downloaded data to {save_path}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e791e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
