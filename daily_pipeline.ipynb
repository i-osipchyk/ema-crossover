{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86e832cd",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17d8480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import islice\n",
    "from typing import List, Dict, Callable, Tuple\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2578b7e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a310e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(symbols: List[str], period: str, interval: str, batch_size: int = 100, delay: float = 0.1) -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Download OHLCV data for multiple symbols using Yahoo Finance.\n",
    "\n",
    "    Args:\n",
    "        symbols (List[str]): List of ticker symbols to download.\n",
    "        period (str): Data period (e.g., \"1d\", \"5d\", \"1mo\", \"1y\").\n",
    "        interval (str): Candlestick interval (e.g., \"1m\", \"15m\", \"1h\", \"1d\").\n",
    "        batch_size (int, optional): Number of symbols per request batch. Defaults to 100.\n",
    "        delay (float, optional): Delay (in seconds) between batches to avoid rate limiting. Defaults to 0.1.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Mapping of symbol → OHLCV DataFrame.\n",
    "            Each DataFrame contains: Datetime, Open, High, Low, Close, Volume, Symbol.\n",
    "    \"\"\"\n",
    "    results: Dict[str, pd.DataFrame] = {}\n",
    "\n",
    "    num_batches = (len(symbols) - 1) // batch_size + 1\n",
    "    for i in tqdm(range(0, len(symbols), batch_size), desc=\"Downloading batches\", total=num_batches):\n",
    "        batch = symbols[i:i + batch_size]\n",
    "\n",
    "        try:\n",
    "            raw_df = yf.download(\n",
    "                tickers=batch,\n",
    "                period=period,\n",
    "                interval=interval,\n",
    "                group_by=\"ticker\",\n",
    "                progress=False,\n",
    "                threads=True,\n",
    "                ignore_tz=True,\n",
    "                auto_adjust=False\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading batch {batch}: {e}\")\n",
    "            time.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        if raw_df.empty:\n",
    "            time.sleep(delay)\n",
    "            continue\n",
    "\n",
    "        # Normalize structure\n",
    "        raw_df = raw_df.reset_index(drop=False)\n",
    "\n",
    "        if isinstance(raw_df.columns, pd.MultiIndex):\n",
    "            raw_df.columns = [\n",
    "                f\"{symbol}_{field}\" if field else \"Datetime\"\n",
    "                for symbol, field in raw_df.columns\n",
    "            ]\n",
    "        else:\n",
    "            raw_df.columns = [\n",
    "                \"Datetime\" if col == \"Date\" else f\"{batch[0]}_{col}\"\n",
    "                for col in raw_df.columns\n",
    "            ]\n",
    "\n",
    "        # Extract data per symbol\n",
    "        for symbol in batch:\n",
    "            cols = [col for col in raw_df.columns if col.startswith(f\"{symbol}_\")]\n",
    "            if not cols:\n",
    "                continue\n",
    "\n",
    "            df_symbol = raw_df[[\"Datetime\"] + cols].copy()\n",
    "            df_symbol.columns = [\n",
    "                col.split(\"_\", 1)[1] if \"_\" in col else col\n",
    "                for col in df_symbol.columns\n",
    "            ]\n",
    "            df_symbol[\"Symbol\"] = symbol\n",
    "\n",
    "            results[symbol] = df_symbol\n",
    "\n",
    "        time.sleep(delay)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a45781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_list_to_file(data: List[str], filepath: str) -> None:\n",
    "    \"\"\"\n",
    "    Write a list of strings to a file as comma-separated values.\n",
    "\n",
    "    Args:\n",
    "        data (List[str]): List of strings to write.\n",
    "        filepath (str): Path to the output file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(\",\".join(data))\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Failed to write to file {filepath}: {e}\")\n",
    "\n",
    "def read_list_from_file(filepath: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Read a comma-separated list of strings from a file.\n",
    "\n",
    "    Args:\n",
    "        filepath (str): Path to the input file.\n",
    "\n",
    "    Returns:\n",
    "        List[str]: List of strings read from the file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read().strip()\n",
    "            return content.split(\",\") if content else []\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(f\"File not found: {filepath}\")\n",
    "    except Exception as e:\n",
    "        raise IOError(f\"Failed to read from file {filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4a5282e",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list = read_list_from_file(\n",
    "    filepath='data/all-symbols-june-2025.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c06d66da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d803906ff336435baa465de1257e7391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading batches:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['X', 'JNPR']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['AZEK']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['DIST']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['JVSA', 'OCX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['AKYA']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['KRON']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['LRFC']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['LTRY']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['MINM']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['UBX', 'GLYC']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['CEAD', 'EYEN']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "3 Failed downloads:\n",
      "['SNPX', 'LDTC', 'FMTO']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['MRIN', 'KWE']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['SVT', 'SATX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['CHRO']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['IGT']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['EVRI']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['AGS']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['PHX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "2 Failed downloads:\n",
      "['SUP', 'BPT']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['RGLS']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "3 Failed downloads:\n",
      "['DADA', 'SHYF', 'EBTC']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['LSEA']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['SSBK']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "2 Failed downloads:\n",
      "['INZY', 'BROG']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['PBYI']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['CFBK']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['MCHP']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "1 Failed download:\n",
      "['FRHC']: Timeout('Failed to perform, curl: (28) Operation timed out after 10000 milliseconds with 1902 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "\n",
      "2 Failed downloads:\n",
      "['LANC']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "['ESGR']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "\n",
      "1 Failed download:\n",
      "['SWTX']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['PLYA']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['RDFN']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n",
      "\n",
      "1 Failed download:\n",
      "['RDUS']: YFRateLimitError('Too Many Requests. Rate limited. Try after a while.')\n"
     ]
    }
   ],
   "source": [
    "stock_data = download_data(\n",
    "    symbols=symbols_list, \n",
    "    period='1000d', \n",
    "    interval='1d',\n",
    "    batch_size=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76f00b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_dict(\n",
    "    stock_dict: Dict[str, pd.DataFrame],\n",
    "    function: Callable[..., pd.DataFrame],\n",
    "    **kwargs\n",
    ") -> Dict[str, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Apply a transformation function to each DataFrame in a dictionary.\n",
    "\n",
    "    Args:\n",
    "        stock_dict (Dict[str, pd.DataFrame]): Mapping of symbol → DataFrame.\n",
    "        function (Callable[..., pd.DataFrame]): Function to apply to each DataFrame.\n",
    "        **kwargs: Additional keyword arguments for the function.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, pd.DataFrame]: Updated mapping with transformed DataFrames.\n",
    "    \"\"\"\n",
    "    new_stock_dict: Dict[str, pd.DataFrame] = {}\n",
    "    for symbol, df in tqdm(stock_dict.items(), desc=\"Processing symbols\", total=len(stock_dict)):\n",
    "        df_copy = df.copy()\n",
    "        try:\n",
    "            new_stock_dict[symbol] = function(df_copy, **kwargs)\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error processing {symbol}: {e}\")\n",
    "    return new_stock_dict\n",
    "\n",
    "def calculate_ma(df: pd.DataFrame, period: int, source: str = \"Close\", method: str = \"EMA\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate a moving average (EMA or SMA) and add it as a new column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing a source column (e.g., 'Close').\n",
    "        period (int): Lookback period for the moving average.\n",
    "        source (str, optional): Column to calculate MA on. Defaults to \"Close\".\n",
    "        method (str, optional): Type of moving average (\"EMA\" or \"SMA\"). Defaults to \"EMA\".\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new MA column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the source column is missing, if period <= 0, or if method is invalid.\n",
    "        TypeError: If period is not an integer.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if method.upper() == \"EMA\":\n",
    "            ma_series = df[source].ewm(span=period, adjust=False).mean()\n",
    "            ma_series.iloc[:period - 1] = pd.NA\n",
    "        else:  # SMA\n",
    "            ma_series = df[source].rolling(window=period).mean()\n",
    "\n",
    "        col_name = f\"{method.upper()}_{source}_{period}\"\n",
    "        df[col_name] = ma_series\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to calculate {method.upper()} on column '{source}' with period {period}: {e}\")\n",
    "\n",
    "def calculate_atr(df: pd.DataFrame, period: int = 14) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate Average True Range (ATR) and ATR%.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'High', 'Low', and 'Close' columns.\n",
    "        period (int, optional): ATR lookback period. Defaults to 14.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'ATR_{period}' and 'ATR%' columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        high_low = df[\"High\"] - df[\"Low\"]\n",
    "        high_close = (df[\"High\"] - df[\"Close\"].shift()).abs()\n",
    "        low_close = (df[\"Low\"] - df[\"Close\"].shift()).abs()\n",
    "        tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "\n",
    "        atr_col = f\"ATR_{period}\"\n",
    "        df[atr_col] = tr.rolling(period).mean()\n",
    "        df[\"ATR%\"] = df[atr_col] / df[\"Close\"] * 100\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to calculate ATR: {e}\") \n",
    "    \n",
    "def calculate_macd(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate MACD, Signal, and Histogram.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with a 'Close' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'MACD', 'MACD_Signal', 'MACD_Hist' columns.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "        ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "\n",
    "        df[\"MACD\"] = ema12 - ema26\n",
    "        df[\"MACD_Signal\"] = df[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "        df[\"MACD_Hist\"] = df[\"MACD\"] - df[\"MACD_Signal\"]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to calculate MACD: {e}\") \n",
    "\n",
    "def label_candle_color(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Label each candlestick as Green, Red, or Doji.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame with 'Open' and 'Close' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added 'Candle_Color' column.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df[\"Candle_Color\"] = df.apply(\n",
    "            lambda row: (\n",
    "                \"Green\" if row[\"Close\"] > row[\"Open\"]\n",
    "                else \"Red\" if row[\"Close\"] < row[\"Open\"]\n",
    "                else \"Doji\"\n",
    "            ),\n",
    "            axis=1\n",
    "        )\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to label candle color: {e}\") \n",
    "\n",
    "def mark_crossovers(df: pd.DataFrame, short_ma_params: Tuple, long_ma_params: Tuple) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Detect moving average crossovers (Bullish or Bearish).\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the required MA columns.\n",
    "        short_ma_params (Tuple[int, str, str]): (period, source, method) for the short MA.\n",
    "        long_ma_params (Tuple[int, str, str]): (period, source, method) for the long MA.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added crossover signal column.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the required MA columns are missing or periods are invalid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        short_p, short_s, short_m = short_ma_params\n",
    "        long_p, long_s, long_m = long_ma_params\n",
    "\n",
    "        if short_p >= long_p:\n",
    "            raise ValueError(\n",
    "                f\"Short MA must have smaller period than Long MA.\\nFound Short MA Period: {short_p}, Long MA Period: {long_p}\"\n",
    "            )\n",
    "\n",
    "        short_col = f\"{short_m}_{short_s}_{short_p}\"\n",
    "        long_col = f\"{long_m}_{long_s}_{long_p}\"\n",
    "        crossover_col = f\"{short_col}_{long_col}_Crossover\"\n",
    "\n",
    "        if short_col not in df.columns or long_col not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"Required columns '{short_col}' and/or '{long_col}' not found in DataFrame.\"\n",
    "            )\n",
    "\n",
    "        cross_up = (df[short_col] > df[long_col]) & (df[short_col].shift(1) <= df[long_col].shift(1))\n",
    "        cross_down = (df[short_col] < df[long_col]) & (df[short_col].shift(1) >= df[long_col].shift(1))\n",
    "\n",
    "        df[crossover_col] = \"No\"\n",
    "        df.loc[cross_up, crossover_col] = \"Bullish\"\n",
    "        df.loc[cross_down, crossover_col] = \"Bearish\"\n",
    "\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(f\"Failed to calculate MA Crossover: {e}\")  \n",
    "\n",
    "def process_symbol_df(\n",
    "    df: pd.DataFrame,\n",
    "    ma_params: List[int] = [\n",
    "        (8, \"Close\", \"EMA\"), (20, \"Close\", \"EMA\"), (34, \"Close\", \"EMA\"), (50, \"Close\", \"EMA\"), (200, \"Close\", \"EMA\")\n",
    "    ],\n",
    "    crossover_mas: List[Tuple[Tuple[int, str, str], Tuple[int, str, str]]] = [\n",
    "        ((8, \"Close\", \"EMA\"), (20, \"Close\", \"EMA\"))\n",
    "    ]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean OHLCV data and compute multiple technical indicators.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Symbol DataFrame with OHLCV columns.\n",
    "        ma_params (List[Tuple[int, str, str]], optional): List of MA configs as (period, source, method).\n",
    "        crossover_mas (List[Tuple[Tuple, Tuple]], optional): List of MA crossover pairs.\n",
    "            Example: [((8, \"Close\", \"EMA\"), (20, \"Close\", \"EMA\"))]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with added indicators.\n",
    "    \"\"\"\n",
    "    # Ensure numeric OHLCV\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Round OHLC values\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\"]:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].round(2)\n",
    "\n",
    "    # --- Calculate EMAs, SMAs and above/below flags ---\n",
    "    for period, source, method in ma_params:\n",
    "        df = calculate_ma(df, period=period, source=source, method=method)\n",
    "        ma_col = f\"{method}_{source}_{period}\"\n",
    "        df[f\"Above_{ma_col}\"] = df[\"Close\"] > df[ma_col]\n",
    "\n",
    "    # --- Other indicators ---\n",
    "    df = calculate_atr(df)\n",
    "    df = calculate_macd(df)\n",
    "    df = label_candle_color(df)\n",
    "\n",
    "    # --- Add crossover signals ---\n",
    "    for short_params, long_params in crossover_mas:\n",
    "        df = mark_crossovers(df, short_params, long_params)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afe06e43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f4675d5b0f490591d66d800ec49869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing symbols:   0%|          | 0/5443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_data_labeled = apply_to_dict(stock_data, process_symbol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80e65011",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_potential_entries(\n",
    "    stock_data_labeled: Dict[str, pd.DataFrame],\n",
    "    short_ema: int = 8,\n",
    "    long_ema: int = 20,\n",
    "    min_crossover_vol: int = 500_000,\n",
    "    min_price: float = 20.0,\n",
    "    max_atr: float = 5.77,\n",
    "    shift: int = 0,  # 0 = last row, 1 = one row before, etc.\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Scan all stocks and return list of symbols that may have a long entry for a given session.\n",
    "\n",
    "    Args:\n",
    "        stock_data_labeled (dict): Dict of {symbol: DataFrame} with indicators and crossovers.\n",
    "        short_ema (int): Short EMA period.\n",
    "        long_ema (int): Long EMA period.\n",
    "        min_crossover_vol (int): Minimum volume on crossover day.\n",
    "        min_price (float): Minimum entry price.\n",
    "        max_atr (float): Maximum ATR% allowed.\n",
    "        shift (int): Number of rows to shift backwards (0 = last row).\n",
    "\n",
    "    Returns:\n",
    "        List[str]: Symbols that may have entry setups.\n",
    "    \"\"\"\n",
    "    candidates = []\n",
    "\n",
    "    crossover_col = f\"EMA_Close_{short_ema}_EMA_Close_{long_ema}_Crossover\"\n",
    "\n",
    "    for symbol, df in stock_data_labeled.items():\n",
    "        if df.empty or shift >= len(df):\n",
    "            continue\n",
    "\n",
    "        last_row = df.iloc[-1 - shift]  # shifted row\n",
    "\n",
    "        if crossover_col not in df.columns or last_row[crossover_col] != \"Bullish\":\n",
    "            continue\n",
    "\n",
    "        # Build filter condition based on your actual columns\n",
    "        conditions = (\n",
    "            last_row.get(\"Above_EMA_Close_34\", False) &\n",
    "            last_row.get(\"Above_EMA_Close_50\", False) &\n",
    "            last_row.get(\"Above_EMA_Close_200\", False) &\n",
    "            (last_row.get(\"MACD\", 0) > 0) &\n",
    "            (last_row.get(\"MACD_Signal\", 0) < 0) &\n",
    "            (last_row.get(\"Volume\", 0) >= min_crossover_vol) &\n",
    "            (last_row.get(\"Close\", 0) >= min_price) &\n",
    "            (last_row.get(\"ATR%\", 100) <= max_atr)\n",
    "        )\n",
    "\n",
    "        if conditions:\n",
    "            candidates.append(symbol)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "edd4972b",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_entries = find_potential_entries(stock_data_labeled, shift=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b022a50f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
