{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbbf038",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b76b29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import time\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from plotly.subplots import make_subplots\n",
    "from datetime import datetime, timedelta\n",
    "import math\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "from itertools import islice\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f0aad",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a4c80",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "526a38b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(symbols, period, interval, batch_size=100, delay=0.1):\n",
    "    \"\"\"\n",
    "    This function is used to download data for general purposes in a specified format.\n",
    "\n",
    "    Parameter:\n",
    "        symbols (list): List of symbols to download data for.\n",
    "        period (str): Period to download data for. Number + timeframe(d for day, h for hour, m for minute etc.).\n",
    "        interval (str): Candlesticks timeframe. Same format as period.\n",
    "        batch_size (int): Size of the batch. Not to overload scanner.\n",
    "        delay (int): Seconds to wait after each batch. Not to overload scanner.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary in format {symbol: symbol_dataframe}.\n",
    "        Dataframe contains columns: Datetime, Symbol, Open, High, Low, Close, Volume.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "\n",
    "    num_batches = (len(symbols) - 1) // batch_size + 1\n",
    "    for i in tqdm(range(0, len(symbols), batch_size), desc=\"Downloading batches\", total=num_batches):\n",
    "        batch = symbols[i:i + batch_size]\n",
    "\n",
    "        df = yf.download(batch, period=period, interval=interval, group_by=\"ticker\", progress=False, threads=True, ignore_tz=True, auto_adjust=False)\n",
    "\n",
    "        if df.empty:\n",
    "            continue\n",
    "\n",
    "        df = pd.concat([df.reset_index()], axis=1)\n",
    "        df = df.reset_index(drop=True)\n",
    "\n",
    "        # Rename columns if multi-ticker\n",
    "        if isinstance(df.columns, pd.MultiIndex):\n",
    "            df.columns = [\n",
    "                f\"{symbol}_{field}\" if field else \"Datetime\"\n",
    "                for symbol, field in df.columns\n",
    "            ]\n",
    "        else:\n",
    "            df.columns = [\n",
    "                f\"{batch[0]}_{col}\" if col != \"Datetime\" else \"Datetime\"\n",
    "                for col in df.columns\n",
    "            ]\n",
    "\n",
    "        # Separate data per ticker\n",
    "        for symbol in batch:\n",
    "            selected_columns = [col for col in df.columns if col.startswith(f\"{symbol}_\")]\n",
    "            if not selected_columns:\n",
    "                continue\n",
    "            symbol_df = df[[\"Datetime\"] + selected_columns].copy()\n",
    "            symbol_df.columns = [col.split(\"_\", 1)[1] if \"_\" in col else col for col in symbol_df.columns]\n",
    "            symbol_df[\"Symbol\"] = symbol\n",
    "            data[symbol] = symbol_df\n",
    "\n",
    "        time.sleep(delay)\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400283d6",
   "metadata": {},
   "source": [
    "### Calculate Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "67efb0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ema(df, period):\n",
    "    \"\"\"\n",
    "    Calculate a single EMA and return the series.\n",
    "    Only calculate EMA after enough rows exist (period-1 rows will be NaN).\n",
    "    \"\"\"\n",
    "    ema_series = df[\"Close\"].ewm(span=period, adjust=False).mean()\n",
    "    ema_series.iloc[:period-1] = pd.NA  # Optional: NaN for initial rows\n",
    "    return ema_series\n",
    "\n",
    "def calculate_atr(df, period=14):\n",
    "    \"\"\"\n",
    "    Calculate ATR and ATR%\n",
    "    \"\"\"\n",
    "    high_low = df[\"High\"] - df[\"Low\"]\n",
    "    high_close = (df[\"High\"] - df[\"Close\"].shift()).abs()\n",
    "    low_close = (df[\"Low\"] - df[\"Close\"].shift()).abs()\n",
    "    tr = pd.concat([high_low, high_close, low_close], axis=1).max(axis=1)\n",
    "    df[\"ATR_14\"] = tr.rolling(period).mean()\n",
    "    df[\"ATR%\"] = df[\"ATR_14\"] / df[\"Close\"] * 100\n",
    "    return df\n",
    "\n",
    "def calculate_macd(df):\n",
    "    \"\"\"\n",
    "    Calculate MACD indicators\n",
    "    \"\"\"\n",
    "    ema12 = df[\"Close\"].ewm(span=12, adjust=False).mean()\n",
    "    ema26 = df[\"Close\"].ewm(span=26, adjust=False).mean()\n",
    "    df[\"MACD\"] = ema12 - ema26\n",
    "    df[\"MACD_Signal\"] = df[\"MACD\"].ewm(span=9, adjust=False).mean()\n",
    "    df[\"MACD_Hist\"] = df[\"MACD\"] - df[\"MACD_Signal\"]\n",
    "    return df\n",
    "\n",
    "def label_candle_color(df):\n",
    "    \"\"\"\n",
    "    Label candles as Green, Red, or Doji\n",
    "    \"\"\"\n",
    "    df[\"Candle_Color\"] = df.apply(\n",
    "        lambda row: \"Green\" if row[\"Close\"] > row[\"Open\"]\n",
    "        else (\"Red\" if row[\"Close\"] < row[\"Open\"] else \"Doji\"),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def mark_crossovers(df, short_ema, long_ema):\n",
    "    \"\"\"\n",
    "    Mark crossovers between two EMA columns.\n",
    "    True  = short_ema crosses above long_ema\n",
    "    False = short_ema crosses below long_ema\n",
    "    NaN   = all other cases\n",
    "    \"\"\"\n",
    "    col = f\"EMA_Crossover_{short_ema}_{long_ema}\"\n",
    "    cross_up = (df[f\"EMA_{short_ema}\"] > df[f\"EMA_{long_ema}\"]) & (\n",
    "        df[f\"EMA_{short_ema}\"].shift(1) <= df[f\"EMA_{long_ema}\"].shift(1)\n",
    "    )\n",
    "    cross_down = (df[f\"EMA_{short_ema}\"] < df[f\"EMA_{long_ema}\"]) & (\n",
    "        df[f\"EMA_{short_ema}\"].shift(1) >= df[f\"EMA_{long_ema}\"].shift(1)\n",
    "    )\n",
    "\n",
    "    df[col] = pd.Series('No', index=df.index, dtype=\"object\")\n",
    "    df.loc[cross_up, col] = 'Bullish'\n",
    "    df.loc[cross_down, col] = 'Bearish'\n",
    "    return df\n",
    "\n",
    "def process_symbol_df(symbol_df, ema_periods=[8,20,34,50,200], crossover_emas=[(8, 20)]):\n",
    "    \"\"\"\n",
    "    Round OHLC, force numeric types, and calculate all indicators\n",
    "    \"\"\"\n",
    "    # Ensure numeric\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]:\n",
    "        if col in symbol_df.columns:\n",
    "            symbol_df[col] = pd.to_numeric(symbol_df[col], errors='coerce')\n",
    "\n",
    "    # Round OHLC\n",
    "    for col in [\"Open\", \"High\", \"Low\", \"Close\"]:\n",
    "        symbol_df[col] = symbol_df[col].round(2)\n",
    "\n",
    "    # Add symbol column\n",
    "    # symbol_df[\"Symbol\"] = symbol\n",
    "\n",
    "    # --- Calculate EMAs individually ---\n",
    "    for period in ema_periods:\n",
    "        symbol_df[f\"EMA_{period}\"] = calculate_ema(symbol_df, period)\n",
    "        symbol_df[f\"Above_EMA_{period}\"] = symbol_df[\"Close\"] > symbol_df[f\"EMA_{period}\"]\n",
    "\n",
    "    # Other indicators\n",
    "    symbol_df = calculate_atr(symbol_df)\n",
    "    symbol_df = calculate_macd(symbol_df)\n",
    "    symbol_df = label_candle_color(symbol_df)\n",
    "    for ema_1, ema_2 in crossover_emas:\n",
    "        symbol_df = mark_crossovers(symbol_df, ema_1, ema_2)\n",
    "\n",
    "    return symbol_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87addb73",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "93a10cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_to_dict(stock_dict, function, **kwargs):\n",
    "    new_stock_dict = {}\n",
    "    for sym, df in tqdm(stock_dict.items(), desc=\"Processing symbols\", total=len(stock_dict)):\n",
    "        df = df.copy()\n",
    "        df = function(df, **kwargs)\n",
    "        new_stock_dict[sym] = df\n",
    "    return new_stock_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73db975",
   "metadata": {},
   "source": [
    "### Trade Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "0541a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trades(df, short_ema: int, long_ema: int):\n",
    "    trades = []\n",
    "\n",
    "    # Dynamically pick the crossover column name\n",
    "    crossover_col = f\"EMA_Crossover_{short_ema}_{long_ema}\"\n",
    "\n",
    "    for i in range(1, len(df) - 2):  # leave space for entry day\n",
    "        prev = df.iloc[i - 1]\n",
    "        curr = df.iloc[i]\n",
    "        nxt = df.iloc[i + 1]\n",
    "\n",
    "        # Detect bullish crossover using precomputed crossover column\n",
    "        if curr[crossover_col] == 'Bullish' and prev[crossover_col] == 'No':\n",
    "            entry_day = nxt  # enter next candle\n",
    "            crossover_day = curr\n",
    "\n",
    "            # Only enter if new high is made\n",
    "            if entry_day[\"High\"] > crossover_day[\"High\"]:\n",
    "                entry_price = crossover_day[\"High\"]\n",
    "                stop_loss = prev[\"Low\"]  # day before crossover\n",
    "                risk = entry_price - stop_loss\n",
    "                pt1 = entry_price + risk\n",
    "                pt2 = entry_price + 2 * risk\n",
    "\n",
    "                # Trade outcome flags\n",
    "                pt1_hit, pt2_hit, stop_loss_hit = False, False, False\n",
    "                exit_date, exit_price = None, None\n",
    "\n",
    "                # Track forward until exit\n",
    "                for j in range(i + 1, len(df)):\n",
    "                    day = df.iloc[j]\n",
    "\n",
    "                    # Check PT1\n",
    "                    if not pt1_hit and day[\"High\"] >= pt1:\n",
    "                        pt1_hit = True\n",
    "\n",
    "                    # Check PT2\n",
    "                    if day[\"High\"] >= pt2:\n",
    "                        pt2_hit = True\n",
    "                        exit_date, exit_price = day[\"Datetime\"], pt2\n",
    "                        break\n",
    "\n",
    "                    # Check Stop Loss\n",
    "                    if day[\"Low\"] <= stop_loss:\n",
    "                        stop_loss_hit = True\n",
    "                        exit_date, exit_price = day[\"Datetime\"], stop_loss\n",
    "                        break\n",
    "\n",
    "                    # Check EMA cross back\n",
    "                    if day[f\"EMA_{short_ema}\"] < day[f\"EMA_{long_ema}\"]:\n",
    "                        exit_date, exit_price = day[\"Datetime\"], day[\"Close\"]\n",
    "                        break\n",
    "\n",
    "                # Crossover metrics\n",
    "                crossover_vol = crossover_day[\"Volume\"]\n",
    "                crossover_color = \"Bullish\" if crossover_day[\"Close\"] > crossover_day[\"Open\"] else \"Bearish\"\n",
    "\n",
    "                # Candle color at entry\n",
    "                candle_color = (\n",
    "                    \"Green\" if entry_day[\"Close\"] > entry_day[\"Open\"]\n",
    "                    else \"Red\" if entry_day[\"Close\"] < entry_day[\"Open\"]\n",
    "                    else \"Doji\"\n",
    "                )\n",
    "\n",
    "                # ATR %\n",
    "                atr_pct = entry_day[\"ATR_14\"] / entry_day[\"Close\"] * 100\n",
    "\n",
    "                # Append trade\n",
    "                trades.append({\n",
    "                    \"Datetime\": entry_day[\"Datetime\"],\n",
    "                    \"Symbol\": df['Symbol'].values[0],\n",
    "                    \"Crossover_Volume\": crossover_vol,\n",
    "                    \"Crossover_Color\": crossover_color,\n",
    "                    \"Entry Price\": entry_price,\n",
    "                    \"Stop Loss\": stop_loss,\n",
    "                    \"PT1\": pt1,\n",
    "                    \"PT2\": pt2,\n",
    "                    \"PT1_Hit\": pt1_hit,\n",
    "                    \"PT2_Hit\": pt2_hit,\n",
    "                    \"Stop_Loss_Hit\": stop_loss_hit,\n",
    "                    \"Exit Date\": exit_date,\n",
    "                    \"Exit Price\": exit_price,\n",
    "                })\n",
    "\n",
    "    trades = pd.DataFrame(trades)\n",
    "    try:\n",
    "        trades = pd.merge(trades, df, on=[\"Datetime\", \"Symbol\"], how=\"left\")\n",
    "    except Exception as e:\n",
    "        print(f\"Merge error for symbol {df['Symbol'].values[0]}: {e}\")\n",
    "\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934b21bd",
   "metadata": {},
   "source": [
    "## Explore Trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1dc0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_data = pd.read_csv('data/all_symbols_results_june_2025.csv', index_col=0).dropna().reset_index(drop=True)\n",
    "symbols_list = list(symbols_data['Symbol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "05dabb70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 1 of 55\n",
      "Processing batch 2 of 55\n",
      "Processing batch 3 of 55\n",
      "Processing batch 4 of 55\n",
      "Processing batch 5 of 55\n",
      "Processing batch 6 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['JNPR', 'X']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 7 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AZEK']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 8 of 55\n",
      "Processing batch 9 of 55\n",
      "Processing batch 10 of 55\n",
      "Processing batch 11 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['DIST']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 12 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8 Failed downloads:\n",
      "['JVSA', 'OCX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n",
      "['SNCR', 'NSPR', 'GGR', 'FOSL', 'MAMO']: Timeout('Failed to perform, curl: (28) Connection timed out after 10002 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n",
      "['VEEA']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 13 of 55\n",
      "Processing batch 14 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['KRON']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 15 of 55\n",
      "Processing batch 16 of 55\n",
      "Processing batch 17 of 55\n",
      "Processing batch 18 of 55\n",
      "Processing batch 19 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['GLYC']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 20 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['EYEN', 'CEAD']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 21 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3 Failed downloads:\n",
      "['SNPX', 'FMTO', 'LDTC']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 22 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['KWE', 'MRIN']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 23 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['SVT', 'SATX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 24 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['CHRO']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 25 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['IGT']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 26 of 55\n",
      "Processing batch 27 of 55\n",
      "Processing batch 28 of 55\n",
      "Processing batch 29 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['EVRI']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 30 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['WEAV']: Timeout('Failed to perform, curl: (28) Connection timed out after 10002 milliseconds. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 31 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['AGS']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 32 of 55\n",
      "Processing batch 33 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['PHX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 34 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['BPT', 'SUP']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 35 of 55\n",
      "Processing batch 36 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['RGLS']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 37 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "3 Failed downloads:\n",
      "['EBTC', 'DADA', 'SHYF']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 38 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['LSEA']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 39 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['SSBK']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 40 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['BROG', 'INZY']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 41 of 55\n",
      "Processing batch 42 of 55\n",
      "Processing batch 43 of 55\n",
      "Processing batch 44 of 55\n",
      "Processing batch 45 of 55\n",
      "Processing batch 46 of 55\n",
      "Processing batch 47 of 55\n",
      "Processing batch 48 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "2 Failed downloads:\n",
      "['LANC', 'ESGR']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 49 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['SWTX']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 50 of 55\n",
      "Processing batch 51 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['PLYA']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 52 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['RDFN']: YFPricesMissingError('possibly delisted; no price data found  (period=1000d) (Yahoo error = \"No data found, symbol may be delisted\")')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 53 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['WBTN']: Timeout('Failed to perform, curl: (28) Operation timed out after 10002 milliseconds with 588 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 54 of 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "1 Failed download:\n",
      "['BRKL']: Timeout('Failed to perform, curl: (28) Operation timed out after 10001 milliseconds with 0 bytes received. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 55 of 55\n"
     ]
    }
   ],
   "source": [
    "stock_data = download_data(symbols=symbols_list, period='1000d', interval='1d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0b8456cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1deb341ed8477b8f3024cb05277fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing symbols:   0%|          | 0/5443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stock_data_labeled = apply_to_dict(stock_data, process_symbol_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e326e08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafd50ff51844aee86180839fdde0c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating trades:   0%|          | 0/5443 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merge error for symbol X: 'Datetime'\n",
      "Merge error for symbol JNPR: 'Datetime'\n",
      "Merge error for symbol AZEK: 'Datetime'\n",
      "Merge error for symbol HMR: 'Datetime'\n",
      "Merge error for symbol LHSW: 'Datetime'\n",
      "Merge error for symbol BKHA: 'Datetime'\n",
      "Merge error for symbol HSPT: 'Datetime'\n",
      "Merge error for symbol KIDZ: 'Datetime'\n",
      "Merge error for symbol FSHP: 'Datetime'\n",
      "Merge error for symbol DIST: 'Datetime'\n",
      "Merge error for symbol MAMO: 'Datetime'\n",
      "Merge error for symbol JVSA: 'Datetime'\n",
      "Merge error for symbol YHNA: 'Datetime'\n",
      "Merge error for symbol ASPC: 'Datetime'\n",
      "Merge error for symbol GGR: 'Datetime'\n",
      "Merge error for symbol EURK: 'Datetime'\n",
      "Merge error for symbol RDAC: 'Datetime'\n",
      "Merge error for symbol OCX: 'Datetime'\n",
      "Merge error for symbol NSPR: 'Datetime'\n",
      "Merge error for symbol VEEA: 'Datetime'\n",
      "Merge error for symbol FOSL: 'Datetime'\n",
      "Merge error for symbol SNCR: 'Datetime'\n",
      "Merge error for symbol RCT: 'Datetime'\n",
      "Merge error for symbol LCCC: 'Datetime'\n",
      "Merge error for symbol RIBB: 'Datetime'\n",
      "Merge error for symbol UYSC: 'Datetime'\n",
      "Merge error for symbol OAKU: 'Datetime'\n",
      "Merge error for symbol KRON: 'Datetime'\n",
      "Merge error for symbol AZI: 'Datetime'\n",
      "Merge error for symbol BLIV: 'Datetime'\n",
      "Merge error for symbol HCAI: 'Datetime'\n",
      "Merge error for symbol OFAL: 'Datetime'\n",
      "Merge error for symbol BOWN: 'Datetime'\n",
      "Merge error for symbol LBGJ: 'Datetime'\n",
      "Merge error for symbol PFAI: 'Datetime'\n",
      "Merge error for symbol TRSG: 'Datetime'\n",
      "Merge error for symbol NCEW: 'Datetime'\n",
      "Merge error for symbol ADVB: 'Datetime'\n",
      "Merge error for symbol STAK: 'Datetime'\n",
      "Merge error for symbol XHLD: 'Datetime'\n",
      "Merge error for symbol CLIK: 'Datetime'\n",
      "Merge error for symbol CHPG: 'Datetime'\n",
      "Merge error for symbol GLYC: 'Datetime'\n",
      "Merge error for symbol AGH: 'Datetime'\n",
      "Merge error for symbol NCI: 'Datetime'\n",
      "Merge error for symbol CEAD: 'Datetime'\n",
      "Merge error for symbol EYEN: 'Datetime'\n",
      "Merge error for symbol LDTC: 'Datetime'\n",
      "Merge error for symbol SNPX: 'Datetime'\n",
      "Merge error for symbol FMTO: 'Datetime'\n",
      "Merge error for symbol MRIN: 'Datetime'\n",
      "Merge error for symbol KWE: 'Datetime'\n",
      "Merge error for symbol SATX: 'Datetime'\n",
      "Merge error for symbol LPA: 'Datetime'\n",
      "Merge error for symbol FLYY: 'Datetime'\n",
      "Merge error for symbol SVT: 'Datetime'\n",
      "Merge error for symbol VNTG: 'Datetime'\n",
      "Merge error for symbol CHRO: 'Datetime'\n",
      "Merge error for symbol IGT: 'Datetime'\n",
      "Merge error for symbol AHL: 'Datetime'\n",
      "Merge error for symbol VOYG: 'Datetime'\n",
      "Merge error for symbol MNTN: 'Datetime'\n",
      "Merge error for symbol EVRI: 'Datetime'\n",
      "Merge error for symbol WEAV: 'Datetime'\n",
      "Merge error for symbol AGS: 'Datetime'\n",
      "Merge error for symbol EQV: 'Datetime'\n",
      "Merge error for symbol AAM: 'Datetime'\n",
      "Merge error for symbol TGE: 'Datetime'\n",
      "Merge error for symbol PHX: 'Datetime'\n",
      "Merge error for symbol BPT: 'Datetime'\n",
      "Merge error for symbol SUP: 'Datetime'\n",
      "Merge error for symbol RGLS: 'Datetime'\n",
      "Merge error for symbol CCCX: 'Datetime'\n",
      "Merge error for symbol DADA: 'Datetime'\n",
      "Merge error for symbol EBTC: 'Datetime'\n",
      "Merge error for symbol MBAV: 'Datetime'\n",
      "Merge error for symbol SHYF: 'Datetime'\n",
      "Merge error for symbol NETD: 'Datetime'\n",
      "Merge error for symbol LSEA: 'Datetime'\n",
      "Merge error for symbol NPAC: 'Datetime'\n",
      "Merge error for symbol GPAT: 'Datetime'\n",
      "Merge error for symbol BACQ: 'Datetime'\n",
      "Merge error for symbol GIG: 'Datetime'\n",
      "Merge error for symbol SSBK: 'Datetime'\n",
      "Merge error for symbol DMAA: 'Datetime'\n",
      "Merge error for symbol CGCT: 'Datetime'\n",
      "Merge error for symbol OYSE: 'Datetime'\n",
      "Merge error for symbol VACH: 'Datetime'\n",
      "Merge error for symbol BEAG: 'Datetime'\n",
      "Merge error for symbol CUB: 'Datetime'\n",
      "Merge error for symbol GSRT: 'Datetime'\n",
      "Merge error for symbol SIMA: 'Datetime'\n",
      "Merge error for symbol RDAG: 'Datetime'\n",
      "Merge error for symbol DRDB: 'Datetime'\n",
      "Merge error for symbol FERA: 'Datetime'\n",
      "Merge error for symbol SZZL: 'Datetime'\n",
      "Merge error for symbol VCIC: 'Datetime'\n",
      "Merge error for symbol AACB: 'Datetime'\n",
      "Merge error for symbol BROG: 'Datetime'\n",
      "Merge error for symbol ANTA: 'Datetime'\n",
      "Merge error for symbol STRZ: 'Datetime'\n",
      "Merge error for symbol CHAC: 'Datetime'\n",
      "Merge error for symbol NHIC: 'Datetime'\n",
      "Merge error for symbol PMTR: 'Datetime'\n",
      "Merge error for symbol WTF: 'Datetime'\n",
      "Merge error for symbol SAFX: 'Datetime'\n",
      "Merge error for symbol INZY: 'Datetime'\n",
      "Merge error for symbol PLMK: 'Datetime'\n",
      "Merge error for symbol FACT: 'Datetime'\n",
      "Merge error for symbol NTWO: 'Datetime'\n",
      "Merge error for symbol ATII: 'Datetime'\n",
      "Merge error for symbol TVAI: 'Datetime'\n",
      "Merge error for symbol MACI: 'Datetime'\n",
      "Merge error for symbol SVCC: 'Datetime'\n",
      "Merge error for symbol GSHR: 'Datetime'\n",
      "Merge error for symbol SDM: 'Datetime'\n",
      "Merge error for symbol IPOD: 'Datetime'\n",
      "Merge error for symbol SPKL: 'Datetime'\n",
      "Merge error for symbol FGMC: 'Datetime'\n",
      "Merge error for symbol WFF: 'Datetime'\n",
      "Merge error for symbol TAVI: 'Datetime'\n",
      "Merge error for symbol EDHL: 'Datetime'\n",
      "Merge error for symbol FATN: 'Datetime'\n",
      "Merge error for symbol QSEA: 'Datetime'\n",
      "Merge error for symbol CHYM: 'Datetime'\n",
      "Merge error for symbol ESGR: 'Datetime'\n",
      "Merge error for symbol LANC: 'Datetime'\n",
      "Merge error for symbol GLXY: 'Datetime'\n",
      "Merge error for symbol MTSR: 'Datetime'\n",
      "Merge error for symbol SWTX: 'Datetime'\n",
      "Merge error for symbol WRD: 'Datetime'\n",
      "Merge error for symbol PLYA: 'Datetime'\n",
      "Merge error for symbol RDFN: 'Datetime'\n",
      "Merge error for symbol DGNX: 'Datetime'\n",
      "Merge error for symbol WBTN: 'Datetime'\n",
      "Merge error for symbol BRKL: 'Datetime'\n",
      "Merge error for symbol NAMM: 'Datetime'\n"
     ]
    }
   ],
   "source": [
    "all_trades = {}\n",
    "for sym, df in tqdm(stock_data_labeled.items(), desc=\"Generating trades\", total=len(stock_data_labeled)):\n",
    "    trades_df = generate_trades(df, short_ema=8, long_ema=20)\n",
    "    all_trades[sym] = trades_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "d7bc168b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_entries = pd.concat([df for df in all_trades.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "61cd7129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered trades: 2299\n",
      "PT1_Hit          0.538495\n",
      "PT2_Hit          0.347977\n",
      "Stop_Loss_Hit    0.461505\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Additional thresholds \n",
    "min_crossover_vol = 2_000_000 # minimum volume at crossover\n",
    "min_price = 50 # minimum entry price \n",
    "\n",
    "# Filter trades combining trend, volatility, price, volume, and candle color \n",
    "filtered_combined = concat_entries[ \n",
    "    (concat_entries[\"Above_EMA_34\"]) & # trend filter \n",
    "    (concat_entries[\"ATR%\"] < concat_entries[\"ATR%\"].median()) & # low volatility \n",
    "    (concat_entries[\"Entry Price\"] >= min_price) & # price filter \n",
    "    (concat_entries[\"Crossover_Volume\"] >= min_crossover_vol) \n",
    "] \n",
    "\n",
    "print(\"Filtered trades:\", len(filtered_combined))\n",
    "print(filtered_combined[[\"PT1_Hit\", \"PT2_Hit\", \"Stop_Loss_Hit\"]].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d95609",
   "metadata": {},
   "source": [
    "#### Best filters are:\n",
    "1. Above 34 EMA\n",
    "2. Lower volatility: ATR less than 0.035494516184041786\n",
    "3. Entry Price higher than 50\n",
    "4. Volume on crossover candle 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "7f0d52a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_stocks = filtered_combined['Symbol'].unique() # [:50]\n",
    "selected_stock_data = {key: value for key, value in stock_data_labeled.items() if key in selected_stocks}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0073be",
   "metadata": {},
   "source": [
    "## Grid Search of Trading Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0567bcc",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aee5341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bullish_bearish_pairs(df, short_ema, long_ema):\n",
    "    col = f'EMA_Crossover_{short_ema}_{long_ema}'\n",
    "    \n",
    "    bullish_indices = df.index[df[col] == \"Bullish\"].tolist()\n",
    "    bearish_indices = df.index[df[col] == \"Bearish\"].tolist()\n",
    "\n",
    "    # Remove first Bearish if it comes before first Bullish\n",
    "    if bearish_indices and bullish_indices and bearish_indices[0] < bullish_indices[0]:\n",
    "        bearish_indices.pop(0)\n",
    "\n",
    "    # Add last index if no Bearish exists after last Bullish\n",
    "    if bullish_indices and (not bearish_indices or bearish_indices[-1] < bullish_indices[-1]):\n",
    "        bearish_indices.append(df.index[-1])\n",
    "\n",
    "    # Pair them one by one\n",
    "    pairs = list(zip(bullish_indices, bearish_indices))\n",
    "\n",
    "    # Ensure all pairs are valid (first < second)\n",
    "    pairs = [(b, r) for b, r in pairs if b < r]\n",
    "\n",
    "    return pairs\n",
    "\n",
    "def simulate_trades(df, short_ema, long_ema, stop_rule, sl_offset_pc, max_tp, be_level):\n",
    "    trades = []\n",
    "\n",
    "    pairs = bullish_bearish_pairs(df, short_ema, long_ema)\n",
    "    for bull_cross, bear_cross in pairs:\n",
    "        # Define trade parameters\n",
    "        trade = {'Symbol': df['Symbol'].values[0], 'stop_rule': stop_rule, 'offset': sl_offset_pc, 'max_tp': max_tp, 'breakeven': be_level}\n",
    "        \n",
    "        # Select days\n",
    "        pre_cross_day = df.iloc[bull_cross - 1]\n",
    "        bull_cross_day = df.iloc[bull_cross]\n",
    "        entry_day = df.iloc[bull_cross + 1] if bull_cross + 1 < len(df) else None\n",
    "\n",
    "        # Set entry price\n",
    "        entry_price = bull_cross_day[\"High\"] if entry_day[\"High\"] > bull_cross_day[\"High\"] else None\n",
    "\n",
    "        # Only enter if new high is made and entry day is not the tail\n",
    "        if entry_day is None or entry_price is None:\n",
    "            continue\n",
    "\n",
    "        # Set stop loss based on rule\n",
    "        if stop_rule == \"crossover\":\n",
    "            stop_loss = bull_cross_day[\"Low\"]\n",
    "        elif stop_rule == \"previous\":\n",
    "            stop_loss = pre_cross_day[\"Low\"]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid stop rule\")\n",
    "        \n",
    "        # Apply stop loss offset\n",
    "        stop_loss -= sl_offset_pc / 100 * (entry_price - stop_loss)\n",
    "\n",
    "        # Filter out trades with invalid stop loss\n",
    "        if stop_loss >= entry_price:\n",
    "            continue\n",
    "\n",
    "        # Calculate risk\n",
    "        risk = entry_price - stop_loss\n",
    "\n",
    "        # Set take profit levels, exit sizes and be price\n",
    "        tp_levels = [entry_price + (i + 1) * risk for i in range(max_tp)]\n",
    "        # tp_sizes = [1.0 / max_tp] * max_tp  # Position sizes for each TP level\n",
    "        # tp_sizes = tp_distribution(max_tp, coefficient=tp_coef)  # Position sizes for each TP level\n",
    "        be_price = entry_price + be_level * risk if be_level > 0 else None\n",
    "\n",
    "        # Set other trade parameters\n",
    "        trade['Datetime'] = entry_day[\"Datetime\"]\n",
    "        trade['EntryPrice'] = entry_price\n",
    "        trade['StopLoss'] = stop_loss\n",
    "        trade['Risk'] = risk\n",
    "        trade['MaxTP'] = tp_levels[-1]\n",
    "        trade['CrossoverVolume'] = bull_cross_day[\"Volume\"]\n",
    "        trade['CrossoverColor'] = bull_cross_day[\"Candle_Color\"]\n",
    "        trade['ExitTypes'] = []\n",
    "        trade['Exits'] = []\n",
    "        \n",
    "        for j in range(bull_cross + 1, bear_cross + 1):\n",
    "            last_tp_hit = False\n",
    "            day = df.iloc[j]\n",
    "\n",
    "            # Check stop loss hit\n",
    "            if day[\"Low\"] <= stop_loss:\n",
    "                # Set type based on stop loss relation to entry\n",
    "                if stop_loss > entry_price:\n",
    "                    exit_type = 'Trailing_SL'\n",
    "                elif stop_loss < entry_price:\n",
    "                    exit_type = 'SL'\n",
    "                else:\n",
    "                    exit_type = 'BE'\n",
    "                trade['ExitTypes'].append(exit_type)\n",
    "                trade['Exits'].append({'Type': exit_type, 'Date': day[\"Datetime\"], 'Price': stop_loss})\n",
    "                break\n",
    "\n",
    "            # Check take profit hits\n",
    "            for idx, tp in enumerate(tp_levels):\n",
    "                if day[\"High\"] >= tp:\n",
    "                    if f'TP{idx+1}' not in trade['ExitTypes']:\n",
    "                        trade['ExitTypes'].append(f'TP{idx+1}')\n",
    "                        trade['Exits'].append({'Type': f'TP{idx+1}', 'Date': day[\"Datetime\"], 'Price': tp})\n",
    "                        stop_loss = tp - 2 * risk if idx >= 1 else be_price\n",
    "                        # Exit if last TP hit\n",
    "                        if idx + 1 == max_tp:\n",
    "                            last_tp_hit = True\n",
    "                            break  # exit TP loop\n",
    "            if last_tp_hit:\n",
    "                break\n",
    "\n",
    "            if j == bear_cross:\n",
    "                trade['ExitTypes'].append('EMA_Cross')\n",
    "                trade['Exits'].append({'Type': 'EMA_Cross', 'Date': day[\"Datetime\"], 'Price': day[\"Close\"]})\n",
    "                break\n",
    "\n",
    "        trades.append(trade)\n",
    "    return trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "id": "eb0a113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search(df, stop_rules, offsets, tp_levels, be_levels):\n",
    "    all_trades = []\n",
    "\n",
    "    # Iterate through all parameter combinations\n",
    "    for stop_rule, offset, tp_level, be_level in itertools.product(stop_rules, offsets, tp_levels, be_levels):\n",
    "\n",
    "        # Run simulation\n",
    "        trades_from_df = simulate_trades(df, 8, 20, stop_rule, offset, tp_level, be_level)\n",
    "\n",
    "        all_trades.append(trades_from_df)\n",
    "\n",
    "    return all_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720f715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_all_results(all_results):\n",
    "    flattened = []\n",
    "\n",
    "    for sym, sym_trades_out in all_results.items():\n",
    "        for sym_trades_in in sym_trades_out:\n",
    "            for trade in sym_trades_in:  # each trade is a dict\n",
    "                for exit_info in trade[\"Exits\"]:\n",
    "                    row = {\n",
    "                        \"Symbol\": trade[\"Symbol\"],\n",
    "                        \"stop_rule\": trade[\"stop_rule\"],\n",
    "                        \"offset\": trade[\"offset\"],\n",
    "                        \"max_tp\": trade[\"max_tp\"],\n",
    "                        \"breakeven\": trade[\"breakeven\"],\n",
    "                        # \"tp_coef\": trade[\"tp_coef\"],\n",
    "                        \"Datetime\": trade[\"Datetime\"],\n",
    "                        \"EntryPrice\": trade[\"EntryPrice\"],\n",
    "                        \"Risk\": trade[\"Risk\"],\n",
    "                        \"StopLoss\": trade[\"StopLoss\"],\n",
    "                        \"MaxTP\": trade[\"MaxTP\"],\n",
    "                        \"CrossoverVolume\": trade.get(\"CrossoverVolume\", None),\n",
    "                        \"CrossoverColor\": trade.get(\"CrossoverColor\", None),\n",
    "                        \"ExitType\": exit_info[\"Type\"],\n",
    "                        \"ExitDate\": exit_info[\"Date\"],\n",
    "                        \"ExitPrice\": exit_info[\"Price\"],\n",
    "                        # \"ExitSize\": exit_info[\"Size\"],\n",
    "                    }\n",
    "                    flattened.append(row)\n",
    "\n",
    "    return pd.DataFrame(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef2f818",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tp_distribution(max_tp, skip_tp=0, coef=1.0):\n",
    "    \"\"\"\n",
    "    Geometric distribution of TP sizes.\n",
    "    \"\"\"\n",
    "    weights = np.array([coef**i for i in range(max_tp-skip_tp)])\n",
    "    weights = weights / weights.sum()\n",
    "    weights = [0.0 for i in range(skip_tp)] + weights.tolist()\n",
    "    return weights\n",
    "\n",
    "def manage_entries_and_exits(flattened_df, group_cols, skip_tp=0, tp_coef=1.0, entry_dist=None):\n",
    "    # Get max tp from the dataframe\n",
    "    max_tp = flattened_df['max_tp'].max()\n",
    "\n",
    "    df = flattened_df.copy()\n",
    "    df[\"ExitSize\"] = 0.0\n",
    "\n",
    "    # Process each trade separately\n",
    "    for trade_id, group in df.groupby(group_cols):\n",
    "        max_tp = group[\"max_tp\"].iloc[0]\n",
    "\n",
    "        # Generate full TP distribution\n",
    "        tp_sizes = tp_distribution(max_tp, skip_tp, coef=tp_coef)\n",
    "\n",
    "        # Assign exit sizes\n",
    "        tp_counter = 0\n",
    "        for idx, row in group.iterrows():\n",
    "            exit_size = 0.0\n",
    "            if row[\"ExitType\"].startswith(\"TP\"):\n",
    "                tp_idx = int(row[\"ExitType\"][2:]) - 1\n",
    "                if tp_idx < len(tp_sizes):\n",
    "                    exit_size = tp_sizes[tp_idx]\n",
    "                    tp_counter += 1\n",
    "            elif row[\"ExitType\"] in [\"SL\", \"BE\", \"Trailing_SL\", \"EMA_Cross\"]:\n",
    "                # Whatever is left after all TPs\n",
    "                exit_size = 1 - sum(tp_sizes[:tp_counter])\n",
    "\n",
    "            df.at[idx, \"ExitSize\"] = exit_size\n",
    "            df.at[idx, \"tp_coef\"] = tp_coef\n",
    "\n",
    "    return df\n",
    "\n",
    "def aggregate_trade(group):\n",
    "    # Weighted average exit price\n",
    "    weighted_exit_price = (group[\"ExitPrice\"] * group[\"ExitSize\"]).sum()\n",
    "    \n",
    "    entry_price = group[\"EntryPrice\"].iloc[0]\n",
    "    risk = group[\"Risk\"].iloc[0]\n",
    "    \n",
    "    # Calculate aggregated results\n",
    "    return pd.Series({\n",
    "        \"WeightedExitPrice\": weighted_exit_price,\n",
    "        \"Return%\": (weighted_exit_price - entry_price) / entry_price * 100,\n",
    "        \"R_Multiple\": (weighted_exit_price - entry_price) / risk,\n",
    "        \"ExitDate\": group[\"ExitDate\"].max(),  # last exit date\n",
    "        \"ExitTypes\": \",\".join(group[\"ExitType\"].tolist())  # track what exits happened\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "id": "1dd2e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_indicators_to_trades(trades_df, historical_data_dict):\n",
    "    enriched_trades = []\n",
    "\n",
    "    for _, trade in trades_df.iterrows():\n",
    "        sym = trade[\"Symbol\"]\n",
    "        dt = trade[\"Datetime\"]\n",
    "\n",
    "        # start with trade row\n",
    "        row = trade.to_dict()\n",
    "\n",
    "        # lookup historical dataframe for this symbol\n",
    "        if sym in historical_data_dict:\n",
    "            hist_df = historical_data_dict[sym]\n",
    "            match = hist_df.loc[hist_df[\"Datetime\"] == dt]\n",
    "\n",
    "            if not match.empty:\n",
    "                # take the first row of matching historical data\n",
    "                hist_data = match.iloc[0].to_dict()\n",
    "\n",
    "                # merge into trade row\n",
    "                row.update(hist_data)\n",
    "\n",
    "        enriched_trades.append(row)\n",
    "\n",
    "    return pd.DataFrame(enriched_trades)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a991046",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8b6351",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2778e6d154f44b0dabcc328e61479489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid search by symbol:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "stop_rules = [\"crossover\"] # crossover is the best option\n",
    "offsets = [0.0, 0.5, 1.0] # not a big impact\n",
    "tp_levels = [6] # 6 is the best option from 1 to 6, but time in the trade increases\n",
    "be_levels = [0.5, 1.0] # 1 loos the best so far\n",
    "\n",
    "# Run grid search across all selected stocks\n",
    "all_results = {}\n",
    "\n",
    "for symbol, df in tqdm(selected_stock_data.items(), desc=\"Grid search by symbol\", total=len(selected_stock_data)):\n",
    "    trades = grid_search(df, stop_rules, offsets, tp_levels, be_levels)\n",
    "    all_results[df['Symbol'].values[0]] = trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "id": "8eeabb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exits = flatten_all_results(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "id": "eac7d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by identifying columns that define a unique trade\n",
    "group_cols = [\n",
    "    \"Symbol\", \"stop_rule\", \"offset\", \"max_tp\", \"breakeven\", \"Datetime\",\n",
    "    \"EntryPrice\", \"Risk\", \"StopLoss\", \"MaxTP\", \"CrossoverVolume\", \"CrossoverColor\"\n",
    "]\n",
    "\n",
    "df_exits = manage_entries_and_exits(df_exits, group_cols, skip_tp=0, tp_coef=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "id": "a6fcb1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_coefs = [1.8, 2.0, 2.2] # best values above 2.0, then low impact\n",
    "position_grid_df = pd.DataFrame()\n",
    "\n",
    "for tp_coef in tp_coefs:\n",
    "    df_exits_temp = manage_entries_and_exits(df_exits, group_cols, skip_tp=0, tp_coef=tp_coef)\n",
    "    position_grid_df = pd.concat([position_grid_df, df_exits_temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "id": "683d93b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_col = True\n",
    "group_cols = group_cols + ([\"tp_coef\"] if tp_col else [])\n",
    "\n",
    "trades_df = position_grid_df.groupby(group_cols).apply(aggregate_trade).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "id": "00c2019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trades_df_historical = add_indicators_to_trades(trades_df, selected_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "id": "4dd9cdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_rule</th>\n",
       "      <th>offset</th>\n",
       "      <th>max_tp</th>\n",
       "      <th>breakeven</th>\n",
       "      <th>tp_coef</th>\n",
       "      <th>EV</th>\n",
       "      <th>Winrate</th>\n",
       "      <th>Trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>crossover</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.269896</td>\n",
       "      <td>0.533727</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.268712</td>\n",
       "      <td>0.534008</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>crossover</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.267701</td>\n",
       "      <td>0.533727</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>crossover</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.267051</td>\n",
       "      <td>0.533165</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.266524</td>\n",
       "      <td>0.534008</td>\n",
       "      <td>7116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_rule  offset  max_tp  breakeven  tp_coef        EV   Winrate  Trades\n",
       "11  crossover     0.5       6        1.0      2.2  0.269896  0.533727    7116\n",
       "17  crossover     1.0       6        1.0      2.2  0.268712  0.534008    7116\n",
       "10  crossover     0.5       6        1.0      2.0  0.267701  0.533727    7116\n",
       "5   crossover     0.0       6        1.0      2.2  0.267051  0.533165    7116\n",
       "16  crossover     1.0       6        1.0      2.0  0.266524  0.534008    7116"
      ]
     },
     "execution_count": 1052,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary = trades_df_historical.groupby(\n",
    "    [\"stop_rule\", \"offset\", \"max_tp\", \"breakeven\", \"tp_coef\"]\n",
    ").agg(EV=(\"R_Multiple\", \"mean\"),\n",
    "       Winrate=(\"Return%\", lambda x: (x > 0).mean()),\n",
    "       Trades=(\"Return%\", \"count\")).reset_index().sort_values(by=\"EV\", ascending=False)\n",
    "\n",
    "summary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "id": "bf092571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stop_rule</th>\n",
       "      <th>offset</th>\n",
       "      <th>max_tp</th>\n",
       "      <th>breakeven</th>\n",
       "      <th>tp_coef</th>\n",
       "      <th>EV</th>\n",
       "      <th>Winrate</th>\n",
       "      <th>Trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.445899</td>\n",
       "      <td>0.592780</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.442220</td>\n",
       "      <td>0.592780</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>crossover</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.442175</td>\n",
       "      <td>0.591336</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>crossover</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.438593</td>\n",
       "      <td>0.591336</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>crossover</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.437112</td>\n",
       "      <td>0.592780</td>\n",
       "      <td>2770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    stop_rule  offset  max_tp  breakeven  tp_coef        EV   Winrate  Trades\n",
       "17  crossover     1.0       6        1.0      2.2  0.445899  0.592780    2770\n",
       "16  crossover     1.0       6        1.0      2.0  0.442220  0.592780    2770\n",
       "11  crossover     0.5       6        1.0      2.2  0.442175  0.591336    2770\n",
       "10  crossover     0.5       6        1.0      2.0  0.438593  0.591336    2770\n",
       "15  crossover     1.0       6        1.0      1.8  0.437112  0.592780    2770"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_crossover_vol = 500_000 # minimum volume at crossover\n",
    "min_price = 20 # minimum entry price \n",
    "\n",
    "# Filter trades combining trend, volatility, price, volume, and candle color \n",
    "trades_df_historical_filtered = trades_df_historical[\n",
    "    (trades_df_historical[\"Above_EMA_34\"]) &\n",
    "    (trades_df_historical[\"CrossoverVolume\"] >= min_crossover_vol) & \n",
    "    (trades_df_historical[\"Above_EMA_200\"]) & \n",
    "    (trades_df_historical[\"Above_EMA_50\"]) &\n",
    "    (trades_df_historical['MACD'] > trades_df_historical['MACD_Signal'])\n",
    "]\n",
    "\n",
    "summary_filtered = trades_df_historical_filtered.groupby(\n",
    "    [\"stop_rule\", \"offset\", \"max_tp\", \"breakeven\", \"tp_coef\"]\n",
    ").agg(EV=(\"R_Multiple\", \"mean\"),\n",
    "       Winrate=(\"Return%\", lambda x: (x > 0).mean()),\n",
    "       Trades=(\"Return%\", \"count\")).reset_index().sort_values(by=\"EV\", ascending=False)\n",
    "\n",
    "summary_filtered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcde6da",
   "metadata": {},
   "source": [
    "#### Correlation with EV:\n",
    "1. Above EMA 34 - highly, positive\n",
    "2. Crossover Volume - moderate, positive until 500K, negative until 2M, then positive again\n",
    "3. Price - slightly, negative\n",
    "4. Above EMA 50 - slightly, positive\n",
    "5. Above EMA 200 - highly, positive\n",
    "6. MACD - slightly, positive\n",
    "\n",
    "*Results from already filtered sample of symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893250aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
